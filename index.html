<!DOCTYPE html>
<html lang="fr">
<head>
	<meta charset="utf-8">
	<title>IA</title>
</head>
<body>
		<table width="100%" >
		<tr>
			<td width="33%" align="left" >
				<video width="100%" autoplay muted loop>
					<source src="videos/pilule_rouge2.mp4" type="video/mp4" />
				</video>
			</td>
			<td width="33%" align="center">
				<img src="images/skynet_resized.jpg" usemap="#skynetReactif" />
			</td>
			<td width="33%" align="right">
				<video width="100%" autoplay muted loop>
					<source src="videos/the_architect.mp4" type="video/mp4" />
				</video>
			</td>
		</tr>
		</table>
	<map name="skynetReactif">
		<area 
			shape="poly" 
			alt="Go to the past"
			title="Go to the past" 
			coords="6,104,65,40,97,70,98,104" 
			href="thePast.html" 
		/>
		<area 
			shape="poly" 
			alt="Go to the future"
			title="Go to the future" 
			coords="108,105,199,103,139,41,108,72" 
			href="theFuture.html" 
		/>
	</map>
	<hr width="100%" size="10" color="#690F0F" />
	<table width="100%" align="left" cellpadding="30px" cellspacing="10px">
	<tr>
	<td align="center" width="25%">
		<b><i>Les débuts de l'IA</i></b>
		<img width="100%" src="images/machine_learning.png" title="les débuts de l'IA" />
		<hr />
		<b><i>L'humain battu au jeu d'échec</i></b>
		<img width="100%" src="images/humain_battu_echec.gif" title="L'humain battu au jeu d'échec"/>
		<hr />
		<b><i>L'IA se perfectionne</i></b>
		<img width="100%" src="images/reseau_neuronal.gif" title="L'IA se perfectionne" />
		<hr />
		<b><i>L'humain battu au jeu de go</i></b>
		<img width="100%" src="images/humain_battu_go.gif" title="L'humain battu au jeu de go"/>
	</td>
	<td width="70%" valign="top">
	<h1 align="center">Stephen Hawking’s final warning for humanity:
	<br />AI is coming for us</h1>
	<p>
	Stephen Hawking’s biggest warning is about the rise of artificial intelligence: It will either be the best 
	thing that’s ever happened to us, or it will be the worst thing. If we’re not careful, it very well 
	may be the last thing.
	</p>
	<p>
	Artificial intelligence holds great opportunity for humanity, encompassing everything from Google’s 
	algorithms to self-driving cars to facial recognition software. The AI we have today, however, is 
	still in its primitive stages. Experts worry about what will happen when that intelligence outpaces 
	us. Or, as Hawking puts it, “Whereas the short-term impact of AI depends on who controls it, the 
	long-term impact depends on whether it can be controlled at all.”
	</p>
	<p>
		This might sound like the stuff of science fiction, but Hawking says dismissing it as such “would 
	be a mistake, and potentially our worst mistake ever.”
	</p>
	<p>
	Compared to robots, we humans are pretty clunky. Limited by the slow pace of evolution, it takes 
	us generations to iterate. Robots, on the other hand, can improve upon their own design a lot 
	faster, and soon, they’ll probably be able to do so without our help. Hawking says this will create 
	an “intelligence explosion” in which machines could exceed our intelligence “by more than ours 
	exceeds that of snails.”
	</p>
	<p>A lot of people think that the threat of AI centers on it becoming malevolent rather than benevolent. 
Hawking disabuses us of this concern, saying that the “real risk with AI isn’t malice, but 
competence.” Basically, AI will be very good at accomplishing its goals; if humans get in the way, 
we could be in trouble.
	</p>
	<p>
“You’re probably not an evil ant-hater who steps on ants out of malice, but if you’re in charge of 
a hydroelectric green-energy project and there’s an anthill in the region to be flooded, too bad 
for the ants. Let’s not place humanity in the position of those ants,” Hawking writes.
	</p>
	<p>
For those still unpersuaded, he suggests a different metaphor. “Why are we so worried about AI? 
Surely humans are always able to pull the plug?” a hypothetical person asks him.
	</p>
	<p>
Hawking answers: “People asked a computer, ‘Is there a God?’ And the computer said, 
‘There is now,’ and fused the plug.”
	</p>
	</td>
		</tr>
	<tr>
	<td align="center">
		<hr />
		<b><i>L'IA se perfectionne</i></b>
		<img width="100%" src="images/virtual_brain.gif" title="L'IA se perfectionne" />
		<hr />
		<b><i>Naissance des androïdes</i></b>
		<img width="100%" src="images/androide.gif" title="Naissance des androïdes" />
		<hr />
		<b><i>L'IA se perfectionne</i></b>
		<img width="100%" src="images/grand_reseau_neural.gif" title="L'IA se perfectionne" />
		<hr />
		<b><i>Spécialisation dans l'éradication des nuisibles</i></b>
		<img width="100%" src="images/matrix_sentinel.gif" title="L'IA se spécialise dans l'éradication des nuisibles" />
	</td>
	<td valign="top">
	<hr />
	<h1 align="center">Elon Musks - ‘Mark my words :
		<br />
		A.I. is far more dangerous than nukes’</h1>
	<p>
		Elon Musk has doubled down on his dire warnings about the danger of artificial intelligence.
		he is resolute, calling those who push against his warnings “fools”.
	</p>
	<p>
		“The biggest issue I see with so-called AI experts is that they think they know more than they do, 
		and they think they are smarter than they actually are,” said Musk. 
		“This tends to plague smart people. They define themselves by their intelligence and they don’t 
		like the idea that a machine could be way smarter than them, so they discount the idea — which 
		is fundamentally flawed.”
	</p>
	<p>
		Based on his knowledge of machine intelligence and its developments, Musk believes there is 
		reason to be worried.
		“I am really quite close, I am very close, to the cutting edge in AI and it scares the hell 
		out of me,” said Musk. “It’s capable of vastly more than almost anyone knows and the rate 
		of improvement is exponential.”
	</p>
	<p>
		Musk worries AI’s development will outpace our ability to manage it in a safe way.
		“So the rate of improvement is really dramatic. We have to figure out some way to ensure 
		that the advent of digital super intelligence is one which is symbiotic with humanity. 
		I think that is the single biggest existential crisis that we face and the most pressing one.”
	</p>
	<p>
		“I am not really all that worried about the short term stuff. 
		Narrow AI is not a species-level risk. It will result in dislocation, in lost jobs,and 
		better weaponry and that kind of thing, but it is not a fundamental species level risk, 
		whereas digital super intelligence is,” explained Musk.
	</p>
	<p>
		“So it is really all about laying the groundwork to make sure that if humanity collectively 
		decides that creating digital super intelligence is the right move, then we should do so 
		very very carefully — very very carefully. This is the most important thing that we could possibly do.”
	</p>
	</td>
	</tr>
	</table>
</body>
</html>